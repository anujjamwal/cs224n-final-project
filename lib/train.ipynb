{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Chain-of-Thought Training\n",
    "\n",
    "Fine-tune Qwen3-0.6B on the OpenMathReasoning Hierarchical CoT dataset using `HCotTrainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Clone the repo (Colab) or configure `sys.path` so that `model` and `training` packages are importable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# When running in Colab, clone the repo and add lib/ to the path\n",
    "if \"google.colab\" in sys.modules:\n",
    "    if not os.path.exists(\"cs224n-final-project\"):\n",
    "        !git clone https://github.com/anujjamwal/cs224n-final-project.git\n",
    "    sys.path.insert(0, \"cs224n-final-project/lib\")\n",
    "else:\n",
    "    # Local: notebook lives inside lib/ already\n",
    "    sys.path.insert(0, os.path.dirname(os.path.abspath(\"__file__\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./hcot-qwen2.5-math-1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "from model import generate, masks\n",
    "from model.model import THOUGHT_TOKEN, SOLUTION_TOKEN, RETURN_TOKEN, SPECIAL_TOKENS\n",
    "from training.trainer import HCotTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-Math-1.5B\"\n",
    "model_repo_id = \"anujjamwal/Qwen2.5-Math-1.5B-hcot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d7ae1c105d404cab9f58869257c571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "  MODEL_NAME,\n",
    "  dtype=torch.bfloat16,\n",
    "  device_map='auto'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": SPECIAL_TOKENS}\n",
    ")\n",
    "\n",
    "# Set chat template with {% generation %} tag so TRL's assistant_only_loss works\n",
    "tokenizer.chat_template = (\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if message['role'] == 'system' %}\"\n",
    "    \"<|im_start|>system\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "    \"{% elif message['role'] == 'user' %}\"\n",
    "    \"<|im_start|>user\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "    \"{% elif message['role'] == 'assistant' %}\"\n",
    "    \"<|im_start|>assistant\\n{% generation %}{{ message['content'] }}{% endgeneration %}<|im_end|>\\n\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    ")\n",
    "\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "model = base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2493464ea2de4c85b63b84c7277e896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ec27024b764ae2988208276d050f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894977f4f6c84dce84b5cd16daaab30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515ac14eed7f46deb386018fbb710854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 99\n",
      "Columns: ['id', 'question', 'expected_answer', 'problem_source', 'generated_solution', 'pass_rate_72b_tir', 'used_in_kaggle', 'hierarchical_cot', 'hierarchical_cot_raw', 'hcot_model']\n",
      "dict_keys(['id', 'question', 'expected_answer', 'problem_source', 'generated_solution', 'pass_rate_72b_tir', 'used_in_kaggle', 'hierarchical_cot', 'hierarchical_cot_raw', 'hcot_model'])\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"anujjamwal/OpenMathReasoning-Sampled-Hierarchical-Cot\"\n",
    "MAX_SEQ_LEN = 2048\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, split=\"train\").filter(lambda ex: len(ex['hierarchical_cot']) > 50)\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Columns: {dataset.column_names}\")\n",
    "print(dataset[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e64e0efaf794462a1c01772fb279f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prompt', 'completion'])\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset in completion format\n",
    "def preprocess_function(example):\n",
    "    prompt = \"Solve the following math problem. Make sure to put the answer (and only answer) inside \\\\boxed{}.\"\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": example[\"question\"]}\n",
    "        ],\n",
    "        \"completion\": [\n",
    "            {\"role\": \"assistant\", \"content\": f\"<think>{example['hierarchical_cot']}</think>\\boxed{{{example['expected_answer']}}}\"}\n",
    "        ],\n",
    "    }\n",
    "\n",
    "completion_dataset = dataset.map(preprocess_function, remove_columns=dataset.column_names)\n",
    "print(completion_dataset[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCotMaskBuilder(masks.MaterialisedMaskMixin):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.thought_token_id = tokenizer.convert_tokens_to_ids(THOUGHT_TOKEN)\n",
    "        self.solution_token_id = tokenizer.convert_tokens_to_ids(SOLUTION_TOKEN)\n",
    "        self.return_token_id = tokenizer.convert_tokens_to_ids(RETURN_TOKEN)\n",
    "\n",
    "    def __call__(self, input_ids, padding_mask):\n",
    "        return self._build_hierarchical_mask(input_ids=input_ids, padding_mask=padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFT Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl\n",
      "  Downloading trl-0.28.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.1)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.12.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: packaging>20.0 in /usr/local/lib/python3.12/dist-packages (from trl) (26.0)\n",
      "Requirement already satisfied: transformers>=4.56.2 in /usr/local/lib/python3.12/dist-packages (from trl) (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (2.0.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.10.0+cu128)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.24.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=1.13.0->peft) (1.3.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.2->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.2->trl) (0.22.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.3)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.25.0->peft) (0.24.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.25.0->peft) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.25.0->peft) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.25.0->peft) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.25.0->peft) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.25.0->peft) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.25.0->peft) (0.1.2)\n",
      "Downloading trl-0.28.0-py3-none-any.whl (540 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.5/540.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install trl peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig\n",
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.05,\n",
    "    r=256,\n",
    "    bias=\"none\",\n",
    "    target_modules=\"all-linear\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    model_init_kwargs={\"dtype\": torch.bfloat16},\n",
    "    hub_model_id=model_repo_id,\n",
    "    packing=True,\n",
    "    assistant_only_loss=True,\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    bf16=True,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=5,\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from typing import Any, Callable\n",
    "from trl import SFTTrainer\n",
    "\n",
    "class HCotSFTTrainer(SFTTrainer):\n",
    "    def __init__(self, attention_mask_func: Callable, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._attention_mask_func = attention_mask_func\n",
    "    \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        inputs: dict[str, torch.Tensor | Any],\n",
    "        return_outputs: bool = False,\n",
    "        num_items_in_batch: torch.Tensor | int | None = None,\n",
    "    ) -> torch.Tensor | tuple[torch.Tensor, Any]:\n",
    "        padding_mask = inputs.get('attention_mask', None)\n",
    "        attention_mask = self._attention_mask_func(input_ids=inputs[\"input_ids\"], padding_mask=padding_mask)\n",
    "        inputs['attention_mask'] = attention_mask\n",
    "        return super().compute_loss(model, inputs, return_outputs, num_items_in_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = HCotSFTTrainer(\n",
    "  model=model,\n",
    "  train_dataset=completion_dataset,\n",
    "  attention_mask_func=HCotMaskBuilder(tokenizer),\n",
    "  args=training_args,\n",
    "  # peft_config=lora_config,\n",
    "  processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1eeb9fc8d734b82abfa61d4382e359e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156bf45e6f34442f9174bb31e2a07cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af953eb4e2e549c7b048c2098b9a6603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e47aac5cee4adc86460648c7fecc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deee7d00830c440d9226ceb1dc49b4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ..._output/training_args.bin: 100%|##########| 5.71kB / 5.71kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11f16242f864b4babe5a6acb644d634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...872687.3140bbd8edc3.578.0: 100%|##########| 19.4kB / 19.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebea1c1d6f742f09b681c2b89b215a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...872776.3140bbd8edc3.578.1: 100%|##########|  442kB /  442kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5b7162056640a3bb9f156d927f9b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...877264.3140bbd8edc3.578.2: 100%|##########|  429kB /  429kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fa9261d1224aacbc6f2d2364e98476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ner_output/tokenizer.json: 100%|##########| 11.4MB / 11.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be094a6c01f4a7297cfc3a2d908f55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ..._output/model.safetensors:   1%|          | 41.9MB / 4.27GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13349371309f45959667bd807b776f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e997f5db6ed44c0296eb61e6736f67a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5458e0fea9f49c0bde73516532e745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec5c7078ac64ac69d268aab542a7a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ..._output/training_args.bin: 100%|##########| 5.71kB / 5.71kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339353be8deb405ea005eb594782407d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...872687.3140bbd8edc3.578.0: 100%|##########| 19.4kB / 19.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8febb9916b9e4e9b9fcbddd8dc7df92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...872776.3140bbd8edc3.578.1: 100%|##########|  442kB /  442kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aa551a89d54507b73a5c1d4d37db7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...877264.3140bbd8edc3.578.2: 100%|##########|  429kB /  429kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6c6adc51a44c95b1576572c2aeb67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ner_output/tokenizer.json: 100%|##########| 11.4MB / 11.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87101a299238412ca76dab94bda6d877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ..._output/model.safetensors:   1%|          | 41.9MB / 4.27GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/anujjamwal/Qwen2.5-Math-1.5B-hcot/commit/5d5f951886d59f7aedee4be9f12b1bdc5077b2c9', commit_message='End of training', commit_description='', oid='5d5f951886d59f7aedee4be9f12b1bdc5077b2c9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/anujjamwal/Qwen2.5-Math-1.5B-hcot', endpoint='https://huggingface.co', repo_type='model', repo_id='anujjamwal/Qwen2.5-Math-1.5B-hcot'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = \"./hcot-qwen2.5-Math-1.5b/final\"\n",
    "trainer.save_model(output_path)\n",
    "tokenizer.save_pretrained(output_path)\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Solve the following math problem. Make sure to put the answer (and only answer) inside \\boxed{}.<|im_end|>\n",
      "<|im_start|>user\n",
      "The radius of the base of a cylinder is increasing at a rate of 0.5 cm/sec while its height is decreasing at a rate of 1.4 cm/sec. At what rate is the volume of the cylinder changing when the radius is 50 cm and the height is 80 cm?<|im_end|>\n",
      " WithTitle\n",
      "<think>  scrição Okay, let's see. I need to find the rate at which the volume of a cylinder is changing when the radius is 50 cm and the height is 80 cm. The problem says the radius is increasing at 0.5 cm per second and the height is decreasing at 1.4 cm per second. Hmm, so related rates problem. I remember that for these kinds of problems, you need to relate the rates of change using derivatives.\n",
      "\n",
      " AMAGE The volume V of a cylinder is given by the formula V = πr²h, right? Where r is the radius and h is the height. Since both r and h are changing with time, I need to find dV/dt, the rate of change of the volume with respect to time. To find dV/dt, I should take the derivative of V with respect to time t. Since r and h are functions of time, I'll need to use the product rule here because V is a product of r² and h.\n",
      "\n",
      " , Wait, but hold on. Let me actually write that down. The volume V is π times r squared times h. So, if I differentiate V with respect to t, using the product rule, since both r and h are functions of t, then:\n",
      "\n",
      "dV/dt = π * [ (d/dt)(r²) * h + r² * (dV/dt) ]\n",
      "\n",
      "But dV/dt is in the second term, which is the rate of change of the volume due to the change in r or h. Wait, but wait, no. Let me think again. Maybe using the product rule on the entire volume formula. Let's see:\n",
      "\n",
      "V = πr²h\n",
      "\n",
      "So, differentiating with respect to t:\n",
      "\n",
      "dV/dt = π * [ (d/dt)(r²) * h + r² * (dV/dt) ]\n",
      "\n",
      "But dV/dt is the rate of change of the volume, which is what we need to find. Wait, actually, the first term is the derivative of r² times h. Let's compute that. The derivative of r² with respect to t is 2r dr/dt. So substituting that back in, we get:\n",
      "\n",
      "dV/dt = π * [ (2r dr/dt) * h + r² * (dV/dt) ]\n",
      "\n",
      "But I need to solve for dV/dt. Let me rearrange the equation to isolate dV/dt on one side.\n",
      "\n",
      "dV/dt - π r² (dV/dt) = 2π r h dr/dt\n",
      "\n",
      "Factor out dV/dt on the left:\n",
      "\n",
      "dV/dt (1 - π r²) = 2π r h dr/dt\n",
      "\n",
      "Then, solve for dV/dt:\n",
      "\n",
      "dV/dt = (2π r h dr/dt) / (1 - π r²) scrição Using the product rule on V = πr²h, dV/dt = (2πrh dr/dt)/(1 - πr²). scrição\n",
      "\n",
      " scrição So now this is the expression for dV/dt. But I need to plug in the given values. The problem states that the radius is increasing at 0.5 cm/s, so dr/dt = 0.5 cm/s. The height is decreasing at 1.4 cm/s, so dh/dt = -1.4 cm/s (negative because height is decreasing). The radius r is 50 cm, and height h is 80 cm. Let's substitute these values into the equation.\n",
      "\n",
      "First, compute the denominator: 1 - πr². 1 is 1, minus π times (50 cm) squared. 50 squared is 2500, so π*2500 ≈ 7854. So 1 - 7854 ≈ -7853. But since π is approximately 3.14, so πr² ≈ 3.14*2500 = 7850. So denominator is 1 - 7850 ≈ -7849. But maybe it's better to use the exact value.\n",
      "\n",
      "Numerical values:\n",
      "\n",
      "Denominator: 1 - π*(50)^2 = 1 - 2500π\n",
      "\n",
      "Numererator: 2π * 50 * (-1.4) = -140π\n",
      "\n",
      "Therefore, dV/dt = (-140π) / (1 - 2500π)\n",
      "\n",
      "But since the denominator is negative (1 is less than 2500π), the entire fraction will be positive. Let's compute:\n",
      "\n",
      "dV/dt = (140π) / (2500π - 1) scrição Using the negative sign from the derivative term and the denominator as negative gives this entire fraction as positive.\n",
      "\n",
      "But how does that break down? Let me check. Wait, when you have a fraction with a negative numerator and a negative denominator (since π is positive in both). So the negatives cancel out, making the entire fraction positive. So:\n",
      "\n",
      "dV/dt = 140π / (2500π - 1)\n",
      "\n",
      "But we can cancel π in the numerator and denominator:\n",
      "\n",
      "dV/dt = 140 / (2500 - 1/π) ≈ 140 / (2500 - 0.318) ≈ 140 / 2499.68) scrição Approximating 1/π ≈ 0.318. So then dV/dt ≈ 140 / 2499.68 ≈ 0.0563. scrição Numerical approximation.  scrição\n",
      "\n",
      "But let me check if I can compute this exactly. Let's compute 2500π in the denominator. Using π ≈ 3.14159, but maybe to be precise, use π as π.\n",
      "\n",
      "So denominator: 2500 - π × 2500 = 2500(1 - π) ≈ 2500 - 7854 ≈ -7854. But since the original denominator is 1 - πr², which is negative, but the numerator is positive, so the fraction is positive. So:\n",
      "\n",
      "dV/dt = 140 / (2500 - π · 2500) = 140 / (2500 - 7854) ≈ 140 / (-7854) ≈ -0.018. But wait, the negative sign from the denominator is canceled by the numerator, so the actual value is 140 / 7854 ≈ 0.01747. So, the volume is increasing at a rate of about 0.01747 cm³ per second. scrição Exact calculation: 140/(2500 - π·2500) ≈ 140 / (2500 - 7854) ≈ 140 / (-7854) ≈ -0.01747. Since the negative sign cancels, the rate is 0.01747 cm³/s. scrição\n",
      "\n",
      " otlin Numerical evaluation gives approximately 0.01747 cm³/s.  完整热榜 Verified using algebraic simplification and numerical approximation. The rate of volume increase is approximately 0.01747 cm³/s.  \n",
      "\n",
      "\n",
      "**Final Answer**\n",
      "The rate at which the volume is changing when the radius is 50 cm and the height is 80 cm is \\boxed{0.01747} cm³/s. ifixed using algebraic differentiation and numerical approximation.  \n",
      "\\boxed{0.01747} \n",
      "</thinkoxed{0.01747} \n",
      "</thinkoxed{0.01747} \n",
      "\\boxed{0.01747} \n",
      "</think> \n",
      "The rate of change of the volume is \\boxed{0.01747} cm³ per second. \n",
      "</thinkoxed{0.01747} \n",
      "</think> \n",
      "\n",
      ",ifixed{\\frac{140}{2500 - \\pi \\cdot 2500} \\approx 0.01747} \n",
      "</think> \n",
      " Numerical evaluation of the expression gives approximately 0.01747 cm³/s.  \n",
      "\n",
      "\n",
      "**Final Answer**\n",
      "The rate at which the volume is changing is \\boxed{0.01747} \\text{cm}^3\\text{s}. \n",
      "\\boxed{0.01747} \n",
      "</thinkoxed{0.01747} \n",
      "</think> \n",
      "\n",
      ", but let me check if I made any miscalculations here. Let me go through each step again to ensure accuracy.\n",
      "\n",
      "Starting from dr/dt = 0.5 cm/s, dh/dt = -1.4 cm/s.\n",
      "\n",
      "The volume is V = πr²h.\n",
      "\n",
      "Since r is increasing at 0.5 cm/s and h is decreasing at 1.4 cm/s,\n",
      "\n",
      "the derivative of V with respect to t is:\n",
      "\n",
      "dV/dt = π*(2\n"
     ]
    }
   ],
   "source": [
    "example = completion_dataset[9]\n",
    "messages = example[\"prompt\"]  # list of message dicts, e.g. [{\"role\": \"user\", \"content\": \"...\"}]\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    ").to(model.device)\n",
    "\n",
    "thought_token_id = tokenizer.convert_tokens_to_ids(THOUGHT_TOKEN)\n",
    "solution_token_id = tokenizer.convert_tokens_to_ids(SOLUTION_TOKEN)\n",
    "return_token_id = tokenizer.convert_tokens_to_ids(RETURN_TOKEN)\n",
    "\n",
    "gen_out = model.generate(\n",
    "    **inputs,\n",
    "    thought_token_id=thought_token_id,\n",
    "    solution_token_id=solution_token_id,\n",
    "    return_token_id=return_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    use_cache=False,\n",
    "    custom_generate=generate.generate,\n",
    ")\n",
    "\n",
    "print(\"\\n\".join(tokenizer.batch_decode(gen_out)).replace(\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Solve the following math problem. Make sure to put the answer (and only answer) inside \\boxed{}.<|im_end|>\n",
      "<|im_start|>user\n",
      "The radius of the base of a cylinder is increasing at a rate of 0.5 cm/sec while its height is decreasing at a rate of 1.4 cm/sec. At what rate is the volume of the cylinder changing when the radius is 50 cm and the height is 80 cm?<|im_end|>\n",
      " WithTitle\n",
      "<think>  scrição Okay, let's see. I need to find the rate at which the volume of a cylinder is changing when the radius is 50 cm and the height is 80 cm. The problem says the radius is increasing at 0.5 cm per second and the height is decreasing at 1.4 cm per second. Hmm, so related rates problem. I remember that for these kinds of problems, you need to relate the rates of change using derivatives.\n",
      "\n",
      " AMAGE First, let me recall the formula for the volume of a cylinder. The volume V is πr²h, right? Where r is the radius and h is the height. Since both r and h are changing with time, I need to find dV/dt, the rate of change of the volume with respect to time.\n",
      "\n",
      "  scrição To find dV/dt, I should take the derivative of the volume formula with respect to time t. Using the product rule because both r and h are functions of time. Let me write that out. So, derivative of V with respect to t is derivative of πr²h with respect to t. Since π is a constant, it stays outside the derivative. So, π times the derivative of r²h.\n",
      "\n",
      "  scrição Now, the derivative of r²h. Since both r and h are functions of t, I need to use the product rule here. The product rule states that the derivative of two functions multiplied together is the derivative of the first times the second plus the first times the derivative of the second. So, in this case, the first function is r², and the second is h.\n",
      "\n",
      "  scrição So, derivative of r² is 2r dr/dt (using the chain rule), and then multiplied by h, plus r² times the derivative of h, which is dh/dt. Putting that all together,   2r dr/dt * h + r² * dh/dt.  scrição Therefore, dV/dt = π [2r dr/dt h + r² dh/dt]. scrição\n",
      "\n",
      "  scrição Now, I need to substitute the given values into this equation. The problem states that the radius is increasing at 0.5 cm/s, so dr/dt = 0.5 cm/s. The height is decreasing at 1.4 cm/s, so dh/dt = -1.4 cm/s (negative because it's decreasing). The radius r is 50 cm, and height h is 80 cm.  scrição Plugging in the values:  2*(50 cm)*(0.5 cm/s)*(80 cm) + (50 cm)^2*(-1.4 cm/s).  scrição Let's compute each term.   2. 2*50*0.5*80 = 2*25*80 = 4000.  2. 50^2 is 2500, so 2500*(-1.4) = -3500.  3. Adding those together: 4000 + (-3500) = 500.   5. Therefore, dV/dt = π*500 cm³/s.   LOGIN dV/dt = π * 500 cm³/s.  ifixed{\\( dV/dt = \\frac{4000\\pi}{3} \\) cm³/s.  \n",
      " \\boxed{\\frac{4000\\pi}{3}} AMAGE</thinkoxed{\\(\\frac{4000\\pi}{3}\\)} \\) AMAGE</thinkoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "</thinkoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "\\boxed{\\frac{4000\\pi}{3}} \n",
      "</thinkoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "</thinkoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "\\(\\frac{4000\\pi}{3}\\) otlined{\\(\\frac{4000\\pi}{3}\\)} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "\\boxed{\\frac{4000\\pi}{3}} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "</thinkoxed{\\( \\frac{4000\\pi}{3} \\)} scrição</think>  \n",
      "The volume is increasing at a rate of \\( \\frac{4000\\pi}{3} \\) cubic centimeters per second.  \n",
      "\\boxed{\\dfrac{4000\\pi}{3}} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "</think>  \n",
      "</thinkoxed{\\( \\frac{4000\\pi}{3} \\)} scrição</think>  \n",
      "\\boxed{\\dfrac{4000\\pi}{3}} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "</think>  \n",
      "The volume increases at \\( \\frac{4000\\pi}{3} \\) cm³/s.  \n",
      "\\boxed{\\dfrac{4000\\pi}{3}} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "\\boxed{\\dfrac{4000\\pi}{3}} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "</think>  \n",
      "The volume is increasing at \\( \\frac{4000\\pi}{3} \\) cm³/s.  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "</think>  \n",
      "\n",
      ", which simplifies to approximately 4.189 cubic centimeters per second, but the exact value is 4000π/3. So, that's the answer.  BASEPATH The rate of change of the volume is \\boxed{\\dfrac{4000\\pi}{3}} cm³/s.  \n",
      "</thinkoxed{\\( \\frac{4000\\pi}{3} \\)} ifixoxed{\\( \\frac{4000\\pi}{3} \\)} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\boxed{\\dfrac{4000\\pi}{3}} ifixoxed{\\( \\frac{4000\\pi}{3} \\)} otlinoxed{\\( \\frac{4000\\pi}{3} \\)} 完整热榜 The rate of change of the volume is \\boxed{\\dfrac{4000\\pi}{3}} \\) cm³/s.  \n",
      "</think>  \n",
      " The volume is increasing at \\( \\frac{4000\\pi}{3} \\) cubic centimeters per second.  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\boxed{\\dfrac{4000\\pi}{3}} ifixoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{4000\\pi}{3}\\) otlinoxed{\\( \\frac{4000\\pi}{3} \\)}  \n",
      "\\(\\frac{\n"
     ]
    }
   ],
   "source": [
    "gen_out2 = model.generate(\n",
    "    **inputs,\n",
    ")\n",
    "\n",
    "print(\"\\n\".join(tokenizer.batch_decode(gen_out2)).replace(\"\\\\n\", \"\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
